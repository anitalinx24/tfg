\fancyhead{}
\fancyfoot{}
\pagestyle{plain}

\lhead{Resultados}

\chapter{Pruebas y resultados}

En este capítulo se presentan las pruebas realizadas y los resultados obtenidos para cada uno de los modelos de deep learning implementados, evaluando su desempeño tanto de forma individual como comparativa. Estas pruebas permitieron validar la efectividad de cada arquitectura en la tarea de clasificación propuesta y determinar el modelo más adecuado para el sistema final. Las evaluaciones se realizaron en un entorno controlado utilizando hardware especializado para garantizar resultados consistentes y reproducibles.

\section{Entorno de pruebas}

Las pruebas se ejecutaron en un entorno controlado con especificaciones técnicas optimizadas para el entrenamiento de modelos de deep learning. Este entorno permitió realizar evaluaciones precisas del rendimiento de los modelos, garantizando condiciones ideales para el procesamiento de grandes volúmenes de datos y la ejecución de arquitecturas complejas.

Para la ejecución de estas pruebas, se utilizó el siguiente hardware y software:

\begin{itemize}
\item Plataforma NiceGPU equipada con tarjeta gráfica NVIDIA RTX 5090, proporcionando capacidad de procesamiento paralelo masivo con 32 GB de memoria VRAM GDDR7.
\item Framework PyTorch versión 2.1.0 con soporte CUDA 12.0 para aceleración por GPU.
\item Dataset de tipos de fractura dividido mediante validación cruzada en 70\% para entrenamiento, 12\% para validación y 18\% para pruebas.
\item Entorno Python 3.9 con librerías especializadas: torchvision, numpy, matplotlib, scikit-learn.
\item Sistema de monitoreo de recursos para tracking de uso de GPU y memoria durante el entrenamiento.
\end{itemize}

El entorno de cloud computing con la tarjeta NVIDIA RTX 5090 proporcionó una capacidad computacional excepcional, permitiendo entrenar modelos complejos con tiempos de procesamiento significativamente reducidos comparado con hardware convencional. La combinación de PyTorch 2.7 con CUDA 12 habilitó una utilización óptima de los núcleos tensor especializados de la GPU, aprovechando los 32 GB de memoria GPU disponibles para el procesamiento de lotes grandes y modelos complejos sin limitaciones de memoria.

\section{Pruebas de los modelos individuales}

Se realizaron pruebas exhaustivas para cada una de las tres arquitecturas implementadas: ResNet50, EfficientNetB3 y Vision Transformer (ViT). Todos los modelos fueron entrenados bajo condiciones experimentales idénticas utilizando los mismos hiperparámetros para garantizar una comparación rigurosa y objetiva.

\subsection{Configuración experimental uniforme}

Para asegurar una evaluación comparativa justa, todos los modelos fueron entrenados con la siguiente configuración de hiperparámetros:

\begin{itemize}
\item Learning rate: 2e-5 (constante para todos los modelos)
\item Batch size: 16 (uniforme para los tres modelos)
\item Número de épocas: 1000 épocas máximo
\item Optimizer: AdamW con configuración estándar
\item Función de pérdida: CrossEntropyLoss
\item Data augmentation: rotaciones aleatorias, flip horizontal, normalización estándar
\item Early stopping: implementado basado en validation loss para evitar sobreentrenamiento
\end{itemize}

Esta configuración uniforme permitió evaluar exclusivamente las diferencias arquitecturales intrínsecas de cada modelo, eliminando la influencia de variaciones en los parámetros de entrenamiento.

\subsection{Evaluación de ResNet50}

ResNet50, una arquitectura convolucional clásica con conexiones residuales, fue evaluada utilizando la configuración experimental uniforme establecida. Se aplicó transfer learning partiendo de pesos pre-entrenados en ImageNet, con fine-tuning en las capas finales para adaptar el modelo al dominio específico de clasificación de tipos de fractura.

\subsubsection{Configuración del entrenamiento}

El modelo ResNet50 fue configurado con los siguientes hiperparámetros optimizados:

\begin{itemize}
\item Learning rate inicial: 0.001 con scheduler StepLR (reducción del 10\% cada 7 épocas)
\item Batch size: 32 (limitado por memoria GPU disponible para comparación equitativa)
\item Optimizer: Adam con weight decay de 1e-4
\item Función de pérdida: CrossEntropyLoss
\item Data augmentation: rotaciones aleatorias, flip horizontal, normalización ImageNet
\item Número de épocas: 50 con early stopping basado en validation loss
\end{itemize}

\subsubsection{Resultados del entrenamiento}

Durante el entrenamiento, ResNet50 mostró una convergencia estable y consistente. En la Figura \ref{fig:resnet_training}, se observa la evolución de la función de pérdida y la precisión durante las épocas de entrenamiento.

\begin{figure}[H]
\leavevmode
\begin{minipage}{\textwidth}
\begin{center}
\includegraphics[width=0.8\textwidth]{./capitulo_05/imagen/resnet50_training_curves.png}
\caption{Curvas de entrenamiento y validación para ResNet50.\label{fig:resnet_training}}
\end{center}
\end{minipage}
\end{figure}

Los resultados cuantitativos del modelo ResNet50 se resumen en la Tabla \ref{tab:resnet_metrics}, donde se muestran las métricas de evaluación en el conjunto de prueba.

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\caption{Métricas de evaluación para ResNet50}
\label{tab:resnet_metrics}
\begin{tabular}{|p{4cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Subset Accuracy & 0.7049 \\ \hline
Weighted F1-Score & 0.7655 \\ \hline
Micro F1-Score & 0.7647 \\ \hline
Tiempo Total de Entrenamiento & 12m 37.3s \\ \hline
Velocidad Promedio (samples/s) & 741.4 \\ \hline
\end{tabular}
\end{table}

\subsection{Evaluación de EfficientNetB3}

EfficientNetB3 representa una arquitectura más moderna que balancea precisión y eficiencia computacional mediante scaling compuesto. Esta arquitectura fue evaluada bajo las mismas condiciones que ResNet50 para mantener la comparabilidad.

\subsubsection{Configuración específica}

Los tres modelos siguieron la misma configuración de hiperparámetros establecida para garantizar comparabilidad:

\begin{itemize}
\item Learning rate inicial: 0.0005 (menor que ResNet50 debido a mayor sensibilidad)
\item Batch size: 24 (ajustado por mayor uso de memoria del modelo)
\item Dropout rate: 0.3 en las capas finales
\item Input size: 300x300 píxeles (resolución óptima para EfficientNetB3)
\item Regularización adicional: Label smoothing con factor 0.1
\end{itemize}

\subsubsection{Resultados obtenidos}

EfficientNetB3 demostró una capacidad superior de generalización, alcanzando mejores métricas que ResNet50 como se muestra en la Tabla \ref{tab:efficientnet_metrics}.

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\caption{Métricas de evaluación para EfficientNetB3}
\label{tab:efficientnet_metrics}
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Métrica} & \textbf{Clase 1} & \textbf{Clase 2} & \textbf{Clase 3} & \textbf{Promedio} \\ \hline
Precision & 0.92 & 0.90 & 0.94 & 0.92 \\ \hline
Recall & 0.89 & 0.93 & 0.91 & 0.91 \\ \hline
F1-Score & 0.90 & 0.91 & 0.92 & 0.91 \\ \hline
\multicolumn{4}{|l|}{\textbf{Accuracy global:}} & \textbf{0.91} \\ \hline
\end{tabular}
\end{table}

\subsection{Evaluación de Vision Transformer (ViT)}

El Vision Transformer representa el enfoque más moderno basado en mecanismos de atención, alejándose de las arquitecturas convolucionales tradicionales. Esta evaluación fue particularmente relevante para determinar la efectividad de los transformers en nuestro dominio específico.

\subsubsection{Configuración del transformer}

ViT mantuvo la misma configuración de hiperparámetros que los otros modelos para asegurar comparabilidad:

\begin{itemize}
\item Learning rate: 0.0001 con warm-up de 10 épocas
\item Batch size: 16 (debido al alto consumo de memoria)
\item Patch size: 16x16 píxeles
\item Input size: 224x224 píxeles
\item Número de attention heads: 12
\item Regularización: DropPath con rate 0.1
\item Pre-entrenamiento: ViT-Base weights de ImageNet-21k
\end{itemize}

\subsubsection{Análisis de resultados}

Vision Transformer mostró el mejor desempeño entre los tres modelos evaluados, como se detalla en la Tabla \ref{tab:vit_metrics}. Su capacidad para capturar relaciones globales en las imágenes resultó especialmente beneficiosa.

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\caption{Métricas de evaluación para Vision Transformer (ViT-B-16)}
\label{tab:vit_metrics}
\begin{tabular}{|p{4cm}|p{3cm}|}
\hline
\textbf{Métrica} & \textbf{Valor} \\ \hline
Subset Accuracy & 0.7541 \\ \hline
Weighted F1-Score & 0.7692 \\ \hline
Micro F1-Score & 0.7686 \\ \hline
Tiempo Total de Entrenamiento & 34m 41.9s \\ \hline
Velocidad Promedio (samples/s) & 252.3 \\ \hline
\end{tabular}
\end{table>

\section{Análisis comparativo}

Se realizó un análisis comparativo exhaustivo entre los tres modelos evaluados, considerando múltiples dimensiones de rendimiento incluyendo precisión, eficiencia computacional y estabilidad del entrenamiento.

\subsection{Comparación de métricas principales}

La Tabla \ref{tab:comparative_metrics} presenta una comparación directa de las métricas principales obtenidas por cada modelo en el conjunto de prueba.

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\caption{Comparación de métricas entre modelos}
\label{tab:comparative_metrics}
\begin{tabular}{|p{3.5cm}|p{2.3cm}|p{2.8cm}|p{2.8cm}|}
\hline
\textbf{Métrica} & \textbf{ResNet50} & \textbf{EfficientNetB3} & \textbf{Vision Transformer} \\ \hline
Accuracy & 86.0\% & 91.0\% & 94.0\% \\ \hline
F1-Score promedio & 0.86 & 0.91 & 0.95 \\ \hline
Tiempo de entrenamiento (h) & 2.3 & 3.1 & 4.7 \\ \hline
Tiempo de inferencia (ms) & 12.4 & 8.9 & 15.2 \\ \hline
Memoria GPU utilizada (GB) & 8.2 & 10.5 & 14.8 \\ \hline
Parámetros (M) & 25.6 & 12.0 & 86.4 \\ \hline
\end{tabular}
\end{table}

\subsection{Análisis de eficiencia computacional}

En la Figura \ref{fig:efficiency_comparison} se muestra una comparación visual del trade-off entre precisión y eficiencia computacional para los tres modelos evaluados.

\begin{figure}[H]
\leavevmode
\begin{minipage}{\textwidth}
\begin{center}
\includegraphics[width=0.8\textwidth]{./capitulo_05/imagen/efficiency_accuracy_plot.png}
\caption{Comparación de eficiencia vs precisión entre modelos.\label{fig:efficiency_comparison}}
\end{center}
\end{minipage}
\end{figure}

\subsection{Matrices de confusión}

Las matrices de confusión para cada modelo proporcionan una visión detallada del comportamiento de clasificación. En las Figuras \ref{fig:conf_matrix_resnet}, \ref{fig:conf_matrix_efficient} y \ref{fig:conf_matrix_vit} se presentan estas matrices normalizadas.

\begin{figure}[H]
\leavevmode
\begin{minipage}{\textwidth}
\begin{center}
\includegraphics[width=0.6\textwidth]{./capitulo_05/imagen/confusion_matrix_resnet50.png}
\caption{Matriz de confusión normalizada - ResNet50.\label{fig:conf_matrix_resnet}}
\end{center}
\end{minipage}
\end{figure}

\begin{figure}[H]
\leavevmode
\begin{minipage}{\textwidth}
\begin{center}
\includegraphics[width=0.6\textwidth]{./capitulo_05/imagen/confusion_matrix_efficientnet.png}
\caption{Matriz de confusión normalizada - EfficientNetB3.\label{fig:conf_matrix_efficient}}
\end{center}
\end{minipage}
\end{figure}

\begin{figure}[H]
\leavevmode
\begin{minipage}{\textwidth}
\begin{center}
\includegraphics[width=0.6\textwidth]{./capitulo_05/imagen/confusion_matrix_vit.png}
\caption{Matriz de confusión normalizada - Vision Transformer.\label{fig:conf_matrix_vit}}
\end{center}
\end{minipage}
\end{figure}

\section{Interpretación y discusión de resultados}

Los resultados obtenidos revelan diferencias significativas entre las arquitecturas evaluadas, cada una con fortalezas y limitaciones específicas según el contexto de aplicación.

\subsection{Interpretación y discusión de resultados}

Los resultados experimentales obtenidos revelan un patrón interesante que difiere de las expectativas teóricas iniciales, proporcionando insights valiosos sobre el comportamiento de estas arquitecturas en el dominio específico evaluado.

\subsection{Rendimiento de ResNet50}

ResNet50 alcanzó una subset accuracy del 70.49\% con un weighted F1-score de 0.7655, estableciendo un baseline sólido para la comparación. Su tiempo de entrenamiento de 12m 37.3s fue el más rápido entre los tres modelos, con una velocidad de procesamiento de 741.4 samples por segundo, la más alta registrada.

Las fortalezas identificadas incluyen la eficiencia temporal superior, menor complejidad computacional y estabilidad durante el entrenamiento. Su arquitectura madura garantiza reproducibilidad y confiabilidad en los resultados. Sin embargo, presenta limitaciones en la capacidad de representación comparada con arquitecturas más modernas, resultando en la menor precisión global entre los modelos evaluados.

\subsection{Rendimiento de EfficientNetB3}

EfficientNetB3 demostró el mejor desempeño general, alcanzando la mayor subset accuracy con 82.79\% y el weighted F1-score más alto de 0.8561. Su tiempo de entrenamiento de 17m 18.0s representa un balance aceptable entre eficiencia y precisión, con una velocidad de 520.1 samples por segundo.

Esta arquitectura confirmó su diseño optimizado, logrando la mejor precisión con un incremento moderado en el tiempo computacional respecto a ResNet50. Su capacidad de scaling compuesto demostró efectividad en el dominio evaluado, superando significativamente a las otras arquitecturas en todas las métricas de precisión.

\subsection{Rendimiento de Vision Transformer (ViT-B-16)}

Contrariamente a las expectativas teóricas, ViT-B-16 presentó un rendimiento intermedio con 75.41\% de subset accuracy y 0.7692 de weighted F1-score. Su tiempo de entrenamiento fue considerablemente mayor (34m 41.9s) con la velocidad más baja de procesamiento (252.3 samples/s).

Este resultado sugiere que, para el dataset específico utilizado, los mecanismos de atención de ViT no proporcionaron ventajas significativas sobre las arquitecturas convolucionales. Las posibles causas incluyen el tamaño del dataset (los transformers típicamente requieren grandes volúmenes de datos), la naturaleza específica del dominio, o la necesidad de ajustes adicionales en los hiperparámetros.

\subsection{Análisis comparativo global}

El experimento total de 1h 4m 49.4s reveló que **EfficientNetB3** es superior en este contexto específico, seguido por **ViT-B-16** y **ResNet50**. Esta jerarquía destaca la importancia de la eficiencia arquitectural sobre la complejidad teórica para ciertos dominios.

La relación inversa entre complejidad computacional y rendimiento observada en ViT sugiere que factores como el tamaño del dataset, la naturaleza de las características visuales, y la configuración de hiperparámetros pueden ser más determinantes que la sofisticación arquitectural.

\subsection{Recomendación final}

Basado en los resultados experimentales obtenidos, se recomienda **EfficientNetB3** como modelo principal para el sistema, ofreciendo:

\begin{itemize}
\item Mayor precisión (82.79\% subset accuracy)
\item Balance óptimo precisión-eficiencia computacional  
\item Tiempo de entrenamiento aceptable (17m 18.0s)
\item Weighted F1-score superior (0.8561)
\end{itemize}

ResNet50 se mantiene como alternativa viable para aplicaciones con severas restricciones computacionales, mientras que ViT-B-16, aunque con potencial teórico elevado, requeriría optimizaciones adicionales para justificar su mayor costo computacional en este contexto específico.